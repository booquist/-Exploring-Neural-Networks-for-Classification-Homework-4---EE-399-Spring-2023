# -Exploring-Neural-Networks-for-Classification-Homework-4---EE-399-Spring-2023
**Author:** Brendan Oquist <br>
**Abstract:** This report focuses on the application of feedforward neural networks for two distinct tasks as part of EE 399 Spring Quarter 2023, Homework #4. The first task involves fitting a three-layer feedforward neural network to a given dataset, using different sets of training and testing data, and comparing the performance of these models to those developed in Homework #1. The second task entails training a feedforward neural network on the MNIST dataset, following the computation of the first 20 PCA modes of the digit images. The performance of this neural network is compared to Long Short-Term Memory (LSTM), Support Vector Machines (SVM), and decision tree classifiers.

## I. Introduction and Overview
In the first task, the dataset from Homework #1 is revisited, and a three-layer feedforward neural network is employed to fit the data. The performance of the neural network is assessed using the least-square error metric on different training and testing sets. A comparison of the neural network model with the models developed in Homework #1 is provided, highlighting the advantages and disadvantages of using neural networks for this dataset.

In the second task, the MNIST dataset is preprocessed and the first 20 PCA modes of the digit images are computed to perform dimensionality reduction. A feedforward neural network is trained to classify the handwritten digits, and its performance is compared to LSTM, SVM, and decision tree classifiers. The report provides insights into the strengths and weaknesses of these methods for digit recognition tasks and discusses the implications of using feedforward neural networks for image classification problems in the context of machine learning and computer vision.
